import re
import os
import gzip
import json
import pandas as pd
from glob import glob

################################################################################
### Fetch data from config file

configfile: "workflow/config.yaml"
PACKAGE_DIR = config.get("package_dir", None)
VERSION = config.get("version", None)
BARCODEMAPPER_DB = config.get("barcodemapper_db", None)
BARCODEMAPPER_DB_HEADERS = config.get("barcodemapper_db_headers", None)
BOLD_DB = config.get("bold_db", None)
UNITE_DB = config.get("unite_db", None)
BOLD_RETAIN = config.get("bold_retain", None)
UNITE_RETINE = config.get("unite_retain", None)
OUTPUT_FILE = config.get("output_file", None)
TMP_DIR = config.get("tmp_dir", None)
BUILD_ONLY = config.get("build_only", None)
REPORT_FILE = config.get("report_file", None)
MAX_MISMATCHES = config.get("max_mismatches", None)
MIN_COVERAGE = config.get("min_coverage", None)

################################################################################
### Input data

if BUILD_ONLY == "no":

    with open(f"{TMP_DIR}/data/sample_to_reads1.json", "r") as f:
        SAMPLE_TO_READS1 = json.load(f)

    with open(f"{TMP_DIR}/data/sample_to_reads2.json", "r") as f:
        SAMPLE_TO_READS2 = json.load(f)

    samples = list(SAMPLE_TO_READS1.keys())

BARCODEMAPPER_BASE = os.path.splitext(BARCODEMAPPER_DB)[0]
BARCODEMAPPER_1_BT2L = f"{BARCODEMAPPER_BASE}.1.bt2l"
BARCODEMAPPER_2_BT2L = f"{BARCODEMAPPER_BASE}.2.bt2l"
BARCODEMAPPER_3_BT2L = f"{BARCODEMAPPER_BASE}.3.bt2l"
BARCODEMAPPER_4_BT2L = f"{BARCODEMAPPER_BASE}.4.bt2l"
BARCODEMAPPER_rev1_BT2L = f"{BARCODEMAPPER_BASE}.rev.1.bt2l"
BARCODEMAPPER_rev2_BT2L = f"{BARCODEMAPPER_BASE}.rev.2.bt2l"

################################################################################
### Setup the desired outputs

if BUILD_ONLY == "yes":
    rule all:
        input:
            BARCODEMAPPER_DB,
            BARCODEMAPPER_1_BT2L,
            BARCODEMAPPER_2_BT2L,
            BARCODEMAPPER_3_BT2L,
            BARCODEMAPPER_4_BT2L,
            BARCODEMAPPER_rev1_BT2L,
            BARCODEMAPPER_rev2_BT2L,
            BARCODEMAPPER_DB_HEADERS

if BUILD_ONLY == "no":
    rule all:
        input:
            OUTPUT_FILE,
            REPORT_FILE,
            BARCODEMAPPER_DB_HEADERS

################################################################################
### Prepare database

if BOLD_DB or UNITE_DB:

    rule prepare_database:
        input:
            bold=BOLD_DB,
            unite=UNITE_DB
        output:
            BARCODEMAPPER_DB
        threads:
            1
        params:
            package_dir={PACKAGE_DIR},
            bold=BOLD_RETAIN,
            unite=UNITE_RETINE
        resources:
            mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 3) * 2 ** (attempt - 1)),
            runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 5) * 2 ** (attempt - 1))
        message:
            "Preparing database"
        shell:
            """
            python {params.package_dir}/workflow/scripts/prepare_database.py -b {input.bold} -u {input.unite} -x {params.bold} -y {params.unite} -o {output}
            """

################################################################################
### Filter reads with fastp

rule fastp:
    input:
        r1=lambda wildcards: SAMPLE_TO_READS1[wildcards.sample],
        r2=lambda wildcards: SAMPLE_TO_READS2[wildcards.sample]
    output:
        r1 = f"{TMP_DIR}/fastp/{{sample}}_1.fq.gz",
        r2 = f"{TMP_DIR}/fastp/{{sample}}_2.fq.gz",
        fastp_html = f"{TMP_DIR}/fastp/{{sample}}.html",
        fastp_json = f"{TMP_DIR}/fastp/{{sample}}.json"
    threads:
        4
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 5) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 10) * 2 ** (attempt - 1))
    message:
        "Using FASTP to trim adapters and low quality sequences for {wildcards.sample}"
    shell:
        """
        fastp \
            --in1 {input.r1} --in2 {input.r2} \
            --out1 {output.r1} --out2 {output.r2} \
            --trim_poly_g \
            --trim_poly_x \
            --n_base_limit 5 \
            --qualified_quality_phred 20 \
            --length_required 100 \
            --low_complexity_filter 30 \
            --thread {threads} \
            --html {output.fastp_html} \
            --json {output.fastp_json} \
            --adapter_sequence CTGTCTCTTATACACATCT \
            --adapter_sequence_r2 CTGTCTCTTATACACATCT
        """

################################################################################
## Index BarcodeMapper database:

rule index_db:
    input:
        BARCODEMAPPER_DB
    output:
        bt2l1=BARCODEMAPPER_1_BT2L,
        bt2l2=BARCODEMAPPER_2_BT2L,
        bt2l3=BARCODEMAPPER_3_BT2L,
        bt2l4=BARCODEMAPPER_4_BT2L,
        bt2lrev1=BARCODEMAPPER_rev1_BT2L,
        bt2l1rev2=BARCODEMAPPER_rev2_BT2L
    params:
        database = BARCODEMAPPER_BASE
    threads:
        24
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 5) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 30) * 2 ** (attempt - 1))
    message:
        "Indexing unite database with Bowtie2"
    shell:
        """
        bowtie2-build \
            --large-index \
            --threads {threads} \
            {input} {params.database}
        """

################################################################################
## Index BarcodeMapper database:

rule db_headers:
    input:
        BARCODEMAPPER_DB
    output:
        BARCODEMAPPER_DB_HEADERS
    threads:
        1
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 5) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 30) * 2 ** (attempt - 1))
    message:
        "Generating taxonomic overview of database"
    shell:
        """
        grep '^>' {input} | cut -d'|' -f3- | sort -u | tr ';' '\t' > {output}
        """

################################################################################
### Map quality-filtered reads against BarcodeMapper database

rule bowtie2_mapping:
    input:
        bt2l1=BARCODEMAPPER_1_BT2L,
        bt2l2=BARCODEMAPPER_2_BT2L,
        bt2l3=BARCODEMAPPER_3_BT2L,
        bt2l4=BARCODEMAPPER_4_BT2L,
        bt2lrev1=BARCODEMAPPER_rev1_BT2L,
        bt2l1rev2=BARCODEMAPPER_rev2_BT2L,
        r1 = f"{TMP_DIR}/fastp/{{sample}}_1.fq.gz",
        r2 = f"{TMP_DIR}/fastp/{{sample}}_2.fq.gz",
    output:
        bam = f"{TMP_DIR}/bowtie/{{sample}}.bam"
    params:
        database = BARCODEMAPPER_BASE
    threads:
        20
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 5) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 5) * 2 ** (attempt - 1))
    message:
        "Mapping {wildcards.sample} to unite using Bowtie2"
    shell:
        """
        # Map reads to MAGs using Bowtie2
        bowtie2 \
            --time \
            --threads {threads} \
            -x {params.database} \
            -1 {input.r1} \
            -2 {input.r2} \
            -k 10 \
            --seed 1337 \
        | samtools sort -@ {threads} -o {output.bam}
        """

################################################################################
### Extract mapping information from bam file

rule bowtie2_extracting:
    input:
        f"{TMP_DIR}/bowtie/{{sample}}.bam"
    output:
        f"{TMP_DIR}/extract/{{sample}}.tsv"
    params:
        package_dir={PACKAGE_DIR},
        max_mismatches={MAX_MISMATCHES},
        min_coverage={MIN_COVERAGE}
    threads:
        1
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 2) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 5) * 2 ** (attempt - 1))
    message:
        "Extracting taxonomy from bam file of {wildcards.sample}"
    shell:
        """
        python {params.package_dir}/workflow/scripts/extract_taxonomy.py --input {input} --output {output} --max_nm {params.max_mismatches} --min_covered {params.min_coverage}
        """

################################################################################
### Calculate the number of reads assigned to each taxonomic assignment

rule assign_taxonomy:
    input:
        f"{TMP_DIR}/extract/{{sample}}.tsv"
    output:
        f"{TMP_DIR}/taxonomy/{{sample}}.tsv"
    params:
        package_dir={PACKAGE_DIR}
    threads:
        1
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 10) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 2) * 2 ** (attempt - 1))
    message:
        "Assigning taxonomy to {wildcards.sample}"
    script:
        "{params.package_dir}/workflow/scripts/assign_taxonomy.py"

################################################################################
### Aggregate values to obtain an additive quantitative taxonomic hierarchy

rule aggregate_taxonomy:
    input:
        f"{TMP_DIR}/taxonomy/{{sample}}.tsv"
    output:
        f"{TMP_DIR}/aggregate/{{sample}}.tsv"
    params:
        package_dir={PACKAGE_DIR}
    threads:
        1
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 10) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 2) * 2 ** (attempt - 1))
    message:
        "Assigning taxonomy"
    script:
        "{params.package_dir}/workflow/scripts/aggregate_taxonomy.py"

################################################################################
### Merge data from different samples in a final dataset

if BUILD_ONLY == "no":

    rule merge_taxonomy:
        input:
            expand(f"{TMP_DIR}/aggregate/{{sample}}.tsv",sample=samples)
        output:
            OUTPUT_FILE
        params:
            package_dir={PACKAGE_DIR},
            samples=samples
        threads:
            1
        resources:
            mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 10) * 2 ** (attempt - 1)),
            runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 2) * 2 ** (attempt - 1))
        message:
            "Assigning taxonomy"
        script:
            "{params.package_dir}/workflow/scripts/merge_taxonomy.py"

################################################################################
### Generate HTML report

rule html_report:
    input:
        OUTPUT_FILE
    output:
        REPORT_FILE
    threads:
        1
    params:
        package_dir={PACKAGE_DIR},
        version={VERSION}
    resources:
        mem_mb=lambda wildcards, input, attempt: max(8*1024, int(input.size_mb * 3) * 2 ** (attempt - 1)),
        runtime=lambda wildcards, input, attempt: max(10, int(input.size_mb / 1024 * 5) * 2 ** (attempt - 1))
    message:
        "Generating plots"
    shell:
        """
        python {params.package_dir}/workflow/scripts/html_report.py --input {input} --output {output} --version {params.version}
        """
